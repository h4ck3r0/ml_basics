{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees: Making Decisions with Data\n",
    "\n",
    "Welcome to the sixth notebook in our **Machine Learning Basics for Beginners** series! After exploring linear and logistic regression, let's dive into **Decision Trees**, a versatile supervised learning algorithm that can be used for both classification and regression tasks. Decision trees mimic how humans make decisions by asking a series of questions.\n",
    "\n",
    "**What You'll Learn in This Notebook:**\n",
    "- What decision trees are and when to use them.\n",
    "- How decision trees work in simple terms.\n",
    "- A hands-on example of classifying whether someone will play tennis based on weather conditions.\n",
    "- An interactive exercise to build a mini decision tree and see predictions.\n",
    "- Visualizations to understand the tree structure and decision-making process.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What are Decision Trees?\n",
    "\n",
    "**Decision Trees** are a supervised learning algorithm that models decisions as a tree-like structure. Each \"branch\" of the tree represents a decision or question based on a feature, and each \"leaf\" represents an outcome (a class for classification or a value for regression).\n",
    "\n",
    "- **Goal**: Split the data into smaller groups by asking a series of yes/no questions (or thresholds) until reaching a final prediction.\n",
    "- **When to Use It**: Use decision trees for classification (e.g., spam or not spam) or regression (e.g., predicting house prices) when you want an interpretable model that’s easy to understand. They work well with both numerical and categorical data.\n",
    "- **Examples**:\n",
    "  - Classifying if a customer will churn (leave a service) based on usage patterns.\n",
    "  - Predicting house prices based on location, size, and age.\n",
    "  - Deciding if someone should play a sport based on weather conditions.\n",
    "\n",
    "**Analogy**: Imagine you're deciding whether to go outside. You might ask: \"Is it raining?\" If yes, stay in. If no, ask: \"Is it cold?\" If yes, wear a jacket; if no, go out as is. A decision tree works the same way, breaking down a complex decision into a series of simple questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How Do Decision Trees Work?\n",
    "\n",
    "Decision trees work by recursively splitting the data based on features to create a tree structure. Let’s break it down:\n",
    "\n",
    "1. **Start at the Root**: The tree begins with all the data at the \"root node.\"\n",
    "2. **Choose a Feature to Split**: The algorithm picks a feature and a value (or category) to split the data into two or more groups. It chooses the split that best separates the data based on the target (e.g., for classification, it tries to group similar classes together). This is often measured using criteria like \"Gini impurity\" or \"entropy\" (for classification) or variance (for regression).\n",
    "3. **Create Branches**: Each split creates branches leading to new nodes (subgroups of data).\n",
    "4. **Repeat Splitting**: The process repeats for each node, splitting on new features or values until a stopping condition is met (e.g., maximum depth, minimum samples per node, or pure groups).\n",
    "5. **Make Predictions at Leaves**: The final nodes (leaves) contain the predictions. For classification, it’s the most common class in that group; for regression, it’s the average value.\n",
    "\n",
    "**Analogy**: Think of playing a game of \"20 Questions.\" You ask yes/no questions to narrow down possibilities (e.g., \"Is it an animal?\" \"Does it fly?\"), and each answer takes you closer to guessing the object. A decision tree builds a similar flowchart to reach a final answer.\n",
    "\n",
    "**Key Advantage**: Decision trees are easy to interpret—you can follow the path of questions to understand why a prediction was made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Example: Predicting Whether to Play Tennis\n",
    "\n",
    "Let’s see a decision tree in action with a small dataset about whether someone will play tennis based on weather conditions. We’ll use features like outlook, temperature, humidity, and wind.\n",
    "\n",
    "**Dataset** (simplified):\n",
    "- Outlook: Sunny, Sunny, Overcast, Rain, Rain\n",
    "- Temperature: Hot, Hot, Hot, Mild, Cool\n",
    "- Humidity: High, High, High, High, Normal\n",
    "- Wind: Weak, Strong, Weak, Weak, Weak\n",
    "- Play Tennis (Label): No, No, Yes, Yes, Yes\n",
    "\n",
    "We’ll use Python’s `scikit-learn` library to create a decision tree model, train it on this data, and predict for a new day. Focus on the steps and output, not the code details.\n",
    "\n",
    "**Instructions**: Run the code below to see how a decision tree predicts whether to play tennis and visualizes the tree structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a small dataset\n",
    "data = {\n",
    "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain'],\n",
    "    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool'],\n",
    "    'Humidity': ['High', 'High', 'High', 'High', 'Normal'],\n",
    "    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak'],\n",
    "    'Play Tennis': ['No', 'No', 'Yes', 'Yes', 'Yes']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Dataset:\")\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "# Convert categorical data to numerical using LabelEncoder\n",
    "le_outlook = LabelEncoder()\n",
    "le_temp = LabelEncoder()\n",
    "le_humidity = LabelEncoder()\n",
    "le_wind = LabelEncoder()\n",
    "le_play = LabelEncoder()\n",
    "\n",
    "df['Outlook'] = le_outlook.fit_transform(df['Outlook'])\n",
    "df['Temperature'] = le_temp.fit_transform(df['Temperature'])\n",
    "df['Humidity'] = le_humidity.fit_transform(df['Humidity'])\n",
    "df['Wind'] = le_wind.fit_transform(df['Wind'])\n",
    "df['Play Tennis'] = le_play.fit_transform(df['Play Tennis'])\n",
    "\n",
    "# Features and target\n",
    "X = df[['Outlook', 'Temperature', 'Humidity', 'Wind']]\n",
    "y = df['Play Tennis']\n",
    "\n",
    "# Create and train the decision tree model\n",
    "model = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict for a new day: Outlook=Overcast, Temperature=Mild, Humidity=Normal, Wind=Strong\n",
    "new_day = np.array([[le_outlook.transform(['Overcast'])[0], \n",
    "                     le_temp.transform(['Mild'])[0], \n",
    "                     le_humidity.transform(['Normal'])[0], \n",
    "                     le_wind.transform(['Strong'])[0]])\n",
    "prediction = model.predict(new_day)[0]\n",
    "print(f\"New Day (Outlook=Overcast, Temperature=Mild, Humidity=Normal, Wind=Strong): Predicted as {'Yes' if prediction == 1 else 'No'} to Play Tennis\")\n",
    "\n",
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_tree(model, feature_names=['Outlook', 'Temperature', 'Humidity', 'Wind'], \n",
    "          class_names=['No', 'Yes'], filled=True, rounded=True)\n",
    "plt.title('Decision Tree for Playing Tennis')\n",
    "plt.show()\n",
    "\n",
    "print(\"Look at the tree above:\")\n",
    "print(\"- Each box (node) shows a decision based on a feature.\")\n",
    "print(\"- Follow the path based on the conditions to see how a prediction is made.\")\n",
    "print(\"- Colored boxes (leaves) show the final prediction (Yes or No to Play Tennis).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Exercise: Build a Mini Decision Tree Path\n",
    "\n",
    "Now it’s your turn to interact with a decision tree concept! In this exercise, you’ll manually follow a simplified decision path to predict whether to play tennis based on conditions you input. This mimics how a decision tree makes splits.\n",
    "\n",
    "**Instructions**:\n",
    "- Run the code below.\n",
    "- Answer the questions about weather conditions when prompted.\n",
    "- See the prediction based on your inputs and understand the decision path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive exercise to simulate a decision tree path\n",
    "print(\"Welcome to the 'Build a Mini Decision Tree Path' Exercise!\")\n",
    "print(\"Answer questions about weather conditions to predict if you should play tennis.\")\n",
    "print(\"This simulates how a decision tree makes decisions by splitting on features.\\n\")\n",
    "\n",
    "# Start at the root node (first decision)\n",
    "outlook = input(\"What is the Outlook? (Sunny/Overcast/Rain): \").strip().capitalize()\n",
    "if outlook not in ['Sunny', 'Overcast', 'Rain']:\n",
    "    print(\"Invalid input. Defaulting to Sunny.\")\n",
    "    outlook = 'Sunny'\n",
    "\n",
    "if outlook == 'Sunny':\n",
    "    humidity = input(\"What is the Humidity? (High/Normal): \").strip().capitalize()\n",
    "    if humidity not in ['High', 'Normal']:\n",
    "        print(\"Invalid input. Defaulting to High.\")\n",
    "        humidity = 'High'\n",
    "    if humidity == 'High':\n",
    "        print(\"Prediction: No, don't play tennis (Sunny with High Humidity often means No).\")\n",
    "    else:\n",
    "        print(\"Prediction: Yes, play tennis (Sunny with Normal Humidity often means Yes).\")\n",
    "elif outlook == 'Overcast':\n",
    "    print(\"Prediction: Yes, play tennis (Overcast often means Yes, regardless of other conditions).\")\n",
    "else:  # Rain\n",
    "    wind = input(\"What is the Wind? (Strong/Weak): \").strip().capitalize()\n",
    "    if wind not in ['Strong', 'Weak']:\n",
    "        print(\"Invalid input. Defaulting to Strong.\")\n",
    "        wind = 'Strong'\n",
    "    if wind == 'Strong':\n",
    "        print(\"Prediction: No, don't play tennis (Rain with Strong Wind often means No).\")\n",
    "    else:\n",
    "        print(\"Prediction: Yes, play tennis (Rain with Weak Wind often means Yes).\")\n",
    "\n",
    "print(\"\\nThis path shows how a decision tree splits data based on conditions:\")\n",
    "print(f\"- First split on Outlook: {outlook}\")\n",
    "if outlook == 'Sunny':\n",
    "    print(f\"- Then split on Humidity: {humidity}\")\n",
    "elif outlook == 'Rain':\n",
    "    print(f\"- Then split on Wind: {wind}\")\n",
    "print(\"Each answer narrows down the prediction, just like branches in a tree lead to a leaf!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Key Considerations for Decision Trees\n",
    "\n",
    "Decision trees are intuitive and powerful, but they come with some considerations to keep in mind:\n",
    "\n",
    "- **Overfitting Risk**: Decision trees can easily overfit, especially if the tree grows too deep. They might memorize the training data (including noise) instead of learning general patterns, leading to poor performance on new data. Techniques like limiting depth or pruning (cutting off branches) help prevent this.\n",
    "- **Instability**: Small changes in the data can lead to a completely different tree structure, making them less stable compared to other models.\n",
    "- **Bias Toward Simple Splits**: Decision trees often favor features with more categories or values for splits, which might not always be the best choice.\n",
    "\n",
    "**Analogy**: A decision tree is like a very detailed flowchart for decision-making. If you make the flowchart too complicated with every tiny detail, it might only work for the exact situations you’ve seen before and fail for anything new.\n",
    "\n",
    "Despite these issues, decision trees are widely used because they’re easy to understand and form the basis for more advanced methods like Random Forests (which combine many trees to improve performance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Key Takeaways\n",
    "\n",
    "- **Decision Trees** are a supervised learning algorithm for both classification and regression, modeling decisions as a tree of questions and answers.\n",
    "- They work by splitting data based on features to create branches, continuing until a prediction is made at a leaf node.\n",
    "- Use them for tasks like customer churn prediction or price estimation when interpretability is important and data can be split into clear groups.\n",
    "- Be aware of limitations: they can overfit if too complex, are sensitive to data changes, and may bias toward certain features.\n",
    "\n",
    "You’ve now learned a flexible and intuitive algorithm! Decision trees are a stepping stone to understanding more complex ensemble methods and provide a clear way to see how data drives predictions.\n",
    "\n",
    "**What's Next?**\n",
    "Move on to **Notebook 7: K-Nearest Neighbors** to learn about a simple yet effective algorithm for classification and regression based on similarity. See you there!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}