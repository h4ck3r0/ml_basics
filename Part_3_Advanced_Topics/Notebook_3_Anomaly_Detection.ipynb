{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Anomaly Detection\n",
    "\n",
    "Welcome to the third notebook in our advanced machine learning series under **Part_3_Advanced_Topics**. In this notebook, we will explore **Anomaly Detection**, a critical technique for identifying outliers or unusual patterns in data, which is widely used in fraud detection, network security, and quality control.\n",
    "\n",
    "We'll cover the following topics:\n",
    "- What is Anomaly Detection?\n",
    "- Key concepts: Outliers, Novelty Detection, and Types of Anomalies\n",
    "- How Anomaly Detection works\n",
    "- Implementation using scikit-learn\n",
    "- Advantages and limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Anomaly Detection?\n",
    "\n",
    "Anomaly Detection is the process of identifying data points, events, or observations that deviate significantly from the majority of the data or expected behavior. These anomalies, also called outliers, can indicate critical incidents like fraud, system failures, or rare events.\n",
    "\n",
    "Anomaly detection can be applied in supervised, semi-supervised, or unsupervised settings, depending on whether labeled data is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "\n",
    "- **Outliers:** Data points that differ significantly from the rest of the dataset, often due to variability or errors.\n",
    "- **Novelty Detection:** Identifying new, previously unseen patterns that differ from the training data (often used in semi-supervised settings).\n",
    "- **Types of Anomalies:**\n",
    "  - **Point Anomalies:** Individual data points that are anomalous (e.g., a single fraudulent transaction).\n",
    "  - **Contextual Anomalies:** Data points that are anomalous in a specific context (e.g., high temperature in winter).\n",
    "  - **Collective Anomalies:** A collection of data points that are anomalous together (e.g., a sequence of unusual network traffic).\n",
    "- **Unsupervised vs. Supervised:** Unsupervised methods detect anomalies without labeled data, while supervised methods use labeled examples of normal and anomalous data.\n",
    "- **Isolation Forest and One-Class SVM:** Popular algorithms for unsupervised anomaly detection. Isolation Forest isolates anomalies by randomly partitioning data, while One-Class SVM learns a boundary around normal data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Anomaly Detection Works\n",
    "\n",
    "Anomaly detection typically involves the following steps:\n",
    "\n",
    "1. **Data Preparation:** Clean and preprocess the data, handling missing values and scaling features if necessary.\n",
    "2. **Model Selection:** Choose an appropriate algorithm based on the data and problem (e.g., Isolation Forest for unsupervised, One-Class SVM for novelty detection).\n",
    "3. **Training:** Fit the model on normal data (or a mix if unsupervised) to learn the characteristics of typical behavior.\n",
    "4. **Scoring:** Assign anomaly scores or labels to data points based on how much they deviate from the learned normal behavior.\n",
    "5. **Thresholding:** Set a threshold on anomaly scores to classify points as normal or anomalous (often based on domain knowledge or statistical measures).\n",
    "6. **Evaluation:** If labeled data is available, evaluate using metrics like precision, recall, or F1-score for anomaly class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Using scikit-learn\n",
    "\n",
    "Let's implement anomaly detection using scikit-learn with two popular algorithms: Isolation Forest and One-Class SVM. We'll use a synthetic dataset with intentional outliers to demonstrate the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate a synthetic dataset with normal data and outliers\n",
    "np.random.seed(42)\n",
    "# Normal data: two clusters\n",
    "X_normal, _ = make_blobs(n_samples=300, centers=2, n_features=2, cluster_std=0.5, random_state=42)\n",
    "# Outliers: uniformly distributed in a larger range\n",
    "X_outliers = np.random.uniform(low=-6, high=6, size=(30, 2))\n",
    "# Combine normal and outlier data\n",
    "X = np.vstack([X_normal, X_outliers])\n",
    "# Create true labels (1 for normal, -1 for outliers)\n",
    "y_true = np.ones(len(X))\n",
    "y_true[-len(X_outliers):] = -1\n",
    "\n",
    "# 1. Isolation Forest for Anomaly Detection\n",
    "iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "iso_forest.fit(X)\n",
    "y_pred_iso = iso_forest.predict(X)  # Returns 1 for normal, -1 for anomaly\n",
    "\n",
    "# 2. One-Class SVM for Anomaly Detection\n",
    "oc_svm = OneClassSVM(kernel='rbf', nu=0.1)\n",
    "oc_svm.fit(X_normal)  # Train only on normal data for novelty detection\n",
    "y_pred_svm = oc_svm.predict(X)  # Returns 1 for normal, -1 for anomaly\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Isolation Forest results\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_pred_iso, cmap='coolwarm', label='Predicted')\n",
    "plt.title('Isolation Forest Anomaly Detection')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.colorbar(label='Normal (1) / Anomaly (-1)')\n",
    "\n",
    "# Plot One-Class SVM results\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_pred_svm, cmap='coolwarm', label='Predicted')\n",
    "plt.title('One-Class SVM Anomaly Detection')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.colorbar(label='Normal (1) / Anomaly (-1)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the models using classification report (since we have synthetic labels)\n",
    "print('Isolation Forest Classification Report:')\n",
    "print(classification_report(y_true, y_pred_iso, target_names=['Anomaly', 'Normal']))\n",
    "\n",
    "print('One-Class SVM Classification Report:')\n",
    "print(classification_report(y_true, y_pred_svm, target_names=['Anomaly', 'Normal']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages and Limitations\n",
    "\n",
    "**Advantages:**\n",
    "- Identifies rare events or outliers that could indicate critical issues like fraud or system failures.\n",
    "- Works in unsupervised settings, which is useful when labeled anomaly data is scarce.\n",
    "- Can be applied across various domains, from finance to cybersecurity.\n",
    "\n",
    "**Limitations:**\n",
    "- Defining what constitutes an anomaly can be subjective and context-dependent, requiring domain knowledge for thresholding.\n",
    "- High-dimensional data can make anomaly detection challenging due to the curse of dimensionality.\n",
    "- Unsupervised methods may produce false positives or miss subtle anomalies if the model doesn't capture the true distribution of normal data.\n",
    "- Performance heavily depends on the choice of algorithm and hyperparameters (e.g., contamination ratio)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Anomaly Detection is a vital technique for uncovering unusual patterns or events in data, with applications ranging from fraud detection to predictive maintenance. Algorithms like Isolation Forest and One-Class SVM provide effective ways to identify outliers, even in unsupervised settings. Understanding the nature of anomalies and selecting the right method for your data is key to successful implementation.\n",
    "\n",
    "In the next notebook, we will explore another advanced topic to further enhance our machine learning toolkit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}