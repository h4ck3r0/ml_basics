{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Computer Vision\n",
    "\n",
    "Welcome to this notebook on Deep Learning for Computer Vision, part of the 'Part_4_Deep_Learning_and_Specializations' section of our machine learning tutorial series. In this notebook, we'll explore the fundamentals of computer vision using deep learning techniques, focusing on Convolutional Neural Networks (CNNs). CNNs are a powerful class of neural networks designed to process and analyze visual data, making them ideal for tasks like image classification, object detection, and more.\n",
    "\n",
    "## What You'll Learn\n",
    "- The basics of computer vision and its applications in machine learning.\n",
    "- The architecture of Convolutional Neural Networks (CNNs), including convolutional layers, pooling layers, and fully connected layers.\n",
    "- How to build and train a CNN for image classification using TensorFlow and Keras.\n",
    "- Practical implementation on the MNIST dataset for handwritten digit recognition.\n",
    "\n",
    "Let's dive into the fascinating world of computer vision with deep learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Computer Vision\n",
    "\n",
    "Computer vision is a field of artificial intelligence that enables machines to interpret and understand visual information from the world, such as images and videos. It involves tasks like:\n",
    "- **Image Classification**: Identifying what an image represents (e.g., cat vs. dog).\n",
    "- **Object Detection**: Locating and identifying objects within an image.\n",
    "- **Image Segmentation**: Dividing an image into meaningful regions or segments.\n",
    "\n",
    "Deep learning, particularly through CNNs, has revolutionized computer vision by achieving state-of-the-art performance in these tasks. Unlike traditional methods that rely on hand-crafted features, CNNs automatically learn hierarchical feature representations from raw pixel data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding Convolutional Neural Networks (CNNs)\n",
    "\n",
    "CNNs are a specialized type of neural network designed for processing grid-like data, such as images. They are inspired by the human visual system and are particularly effective for tasks involving visual data. The key components of a CNN include:\n",
    "\n",
    "- **Convolutional Layers**: These layers apply filters to the input image to extract features like edges, textures, or patterns. Each filter slides over the image (a process called convolution) to produce feature maps.\n",
    "- **Pooling Layers**: These layers reduce the spatial dimensions of the feature maps (e.g., max pooling takes the maximum value in a region), making the network computationally efficient and reducing overfitting.\n",
    "- **Fully Connected Layers**: At the end of the network, these layers combine the extracted features to make predictions or classifications.\n",
    "- **Activation Functions**: Typically, ReLU (Rectified Linear Unit) is used to introduce non-linearity after convolutional and fully connected layers.\n",
    "\n",
    "CNNs are powerful because they learn hierarchical features: low-level features (like edges) in early layers and high-level features (like object shapes) in deeper layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setting Up the Environment\n",
    "\n",
    "Before we build our CNN, let's import the necessary libraries. We'll use TensorFlow and Keras for building and training the model, and matplotlib for visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loading and Preprocessing the MNIST Dataset\n",
    "\n",
    "We'll use the MNIST dataset, a classic dataset for handwritten digit recognition. It consists of 60,000 training images and 10,000 test images of digits (0-9), each 28x28 pixels in grayscale.\n",
    "\n",
    "Let's load the dataset, normalize the pixel values to the range [0, 1], and reshape the data to include a channel dimension (required for CNNs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset from TensorFlow\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to range [0, 1]\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape data to include channel dimension (28, 28, 1)\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Display dataset shapes\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizing Sample Images\n",
    "\n",
    "Let's visualize a few sample images from the MNIST dataset to understand what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a few sample images\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_train[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'Digit: {np.argmax(y_train[i])}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Building a Convolutional Neural Network\n",
    "\n",
    "Now, let's build a simple CNN model for classifying handwritten digits. Our model will consist of:\n",
    "- Two convolutional layers with ReLU activation and max pooling.\n",
    "- A flatten layer to convert 2D feature maps to a 1D vector.\n",
    "- Two fully connected (dense) layers, with the final layer outputting probabilities for 10 classes (digits 0-9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "model = models.Sequential([\n",
    "    # First Convolutional Block\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Second Convolutional Block\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Flatten the output for dense layers\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    # Dense Layers\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # Output layer for 10 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training the CNN Model\n",
    "\n",
    "Let's train the model on the MNIST training data for 5 epochs. We'll use a batch size of 64 and reserve 20% of the training data for validation to monitor performance during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=5, \n",
    "                    batch_size=64, \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluating the Model\n",
    "\n",
    "After training, let's evaluate the model's performance on the test dataset to see how well it generalizes to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualizing Training Progress\n",
    "\n",
    "Let's plot the training and validation accuracy and loss over the epochs to understand how the model learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Making Predictions\n",
    "\n",
    "Finally, let's use the trained model to make predictions on a few test images and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on a few test images\n",
    "predictions = model.predict(X_test[:10])\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "true_labels = np.argmax(y_test[:10], axis=1)\n",
    "\n",
    "# Visualize predictions\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'Pred: {predicted_labels[i]}\\nTrue: {true_labels[i]}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "\n",
    "In this notebook, we've explored the basics of deep learning for computer vision using Convolutional Neural Networks (CNNs). We built and trained a CNN on the MNIST dataset for handwritten digit recognition, achieving good accuracy on the test set. CNNs are a cornerstone of modern computer vision, and this example is just the beginning. In more advanced applications, CNNs can be used for complex tasks like object detection, facial recognition, and medical image analysis.\n",
    "\n",
    "### Key Takeaways\n",
    "- CNNs are designed to process visual data by learning hierarchical features through convolutional and pooling layers.\n",
    "- Preprocessing data (e.g., normalization) is crucial for effective training.\n",
    "- Visualization of training progress and predictions helps in understanding model performance.\n",
    "\n",
    "Feel free to experiment with the model architecture (e.g., adding more layers, changing hyperparameters) or try other datasets to deepen your understanding of CNNs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Further Exploration\n",
    "\n",
    "If you're interested in diving deeper into computer vision, consider exploring:\n",
    "- **Advanced Architectures**: Learn about architectures like VGG, ResNet, or Inception for more complex tasks.\n",
    "- **Object Detection**: Explore frameworks like YOLO or Faster R-CNN for detecting objects in images.\n",
    "- **Transfer Learning**: Use pre-trained models on custom datasets to leverage existing knowledge (covered in a later notebook in this series).\n",
    "- **Image Augmentation**: Apply techniques to artificially expand your dataset and improve model robustness.\n",
    "\n",
    "Stay tuned for more specialized topics in this 'Part_4_Deep_Learning_and_Specializations' section!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}